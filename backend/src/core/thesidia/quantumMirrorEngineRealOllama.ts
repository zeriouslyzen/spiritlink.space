#!/usr/bin/env ts-node

/**
 * QuantumMirrorEngine + Real Ollama Integration + Multi-Lens Processing
 * 
 * This script demonstrates REAL integration with Ollama and the Hermes model
 * for live paradox resolution and AI-powered symbolic processing through
 * 5 specialized lenses with emergent symbol generation.
 */

import { QuantumMirrorEngine } from './engines/quantumMirrorEngine';
import { EngineInput, SymbolicContext } from './types';
import { MultiLensProcessor, UnifiedKnowledge } from './multiLensProcessor';
import { PureUnicodeGenerator } from './semanticUnicodeGenerator';
import { ThesidiaMasterPromptEngine, ThesidiaAnalysis } from './thesidiaMasterPromptEngine';

// Real Ollama integration
export class RealOllamaService {
  private baseUrl: string;
  private useQuantizedModel: boolean = true;
  private bestQuantizedModel: string = 'llama3.1:8b'; // User's suggestion: FAST model (8B) for speed
  
  // ‚úÖ Better approach - define constants
  private static readonly PERFORMANCE_THRESHOLDS = {
    FAST: 3000,      // Under 3s = FAST
    ACCEPTABLE: 8000, // Under 8s = ACCEPTABLE  
    SLOW: 15000,     // Under 15s = SLOW
    VERY_SLOW: 30000  // Over 30s = VERY SLOW
  } as const;
  
  // User's suggestion: Control output length for true speed comparison
  private static readonly OUTPUT_LENGTH_TARGETS = {
    SHORT: 1000,     // ~200 words
    MEDIUM: 2000,    // ~400 words  
    LONG: 4000       // ~800 words
  } as const;

  // NEW: Multi-Lens Processor for emergent symbolic analysis
  private multiLensProcessor: MultiLensProcessor;
  private symbolGenerator: PureUnicodeGenerator;
  private thesidiaEngine: ThesidiaMasterPromptEngine;

  // NEW: Dynamic Model Router - User's suggestion for next evolution
  private static readonly MODEL_ROUTER = {
    // Simple tasks: Maximum speed, minimal quality requirements
    simple: ['gemma2:2b', 'phi3.5:latest', 'deepseek-coder:latest'],
    // Medium tasks: Balanced speed and quality
    medium: ['llama3.1:8b', 'qwen2.5:latest', 'mistral:latest'],
    // Complex tasks: Maximum quality, speed secondary
    complex: ['nous-hermes2:latest', 'gpt-oss:latest', 'mixtral:latest']
  } as const;

  // ‚úÖ Extract to constants
  private static readonly PARADOX_SCENARIOS = {
    TEMPORAL: 'temporal',
    LOGICAL: 'logical', 
    ONTOLOGICAL: 'ontological',
    SYMBOLIC: 'symbolic'
  } as const;

  // ‚úÖ Extract to constants
  private static readonly PARADOX_PROMPTS = {
    [this.PARADOX_SCENARIOS.TEMPORAL]: 'Generate a complex temporal paradox involving time travel and causality loops. Make it challenging for symbolic analysis. Focus on universal human experiences, not AI-specific scenarios. Ensure the paradox is complete and self-contained. Provide a full, detailed explanation in approximately {length} words.',
    [this.PARADOX_SCENARIOS.LOGICAL]: 'Create a self-referential logical paradox that creates a truth value contradiction. Make it philosophically interesting. Use general philosophical examples, avoid AI self-reference. The paradox should be clear and analyzable. Provide a complete analysis in approximately {length} words.',
    [this.PARADOX_SCENARIOS.ONTOLOGICAL]: 'Generate an ontological paradox about existence, being, and reality. Make it deeply metaphysical. Focus on human consciousness and universal reality, not technological systems. Include multiple layers of contradiction. Provide a comprehensive exploration in approximately {length} words.',
    [this.PARADOX_SCENARIOS.SYMBOLIC]: 'Create a symbolic paradox where meaning collapses into its own negation. Make it artistically profound. Use archetypal human symbols and myths, avoid modern technology references. The paradox should have clear symbolic elements. Provide a detailed interpretation in approximately {length} words.'
  } as const;

  constructor(baseUrl: string = 'http://localhost:11434') {
    this.baseUrl = baseUrl;
    this.multiLensProcessor = new MultiLensProcessor();
    this.symbolGenerator = new PureUnicodeGenerator();
    this.thesidiaEngine = new ThesidiaMasterPromptEngine();
  }

  // NEW: Dynamic Model Selection Based on Task Complexity
  private async selectOptimalModel(taskComplexity: 'simple' | 'medium' | 'complex'): Promise<string> {
    try {
      const response = await fetch(`${this.baseUrl}/api/tags`);
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      const models = await response.json() as any;
      
      // ‚úÖ Validate response structure
      if (!models || !Array.isArray(models.models)) {
        throw new Error('Invalid response format from Ollama API');
      }
      
      const availableModels = models.models;
      
      // Get available models for the task complexity level
      const targetModels = RealOllamaService.MODEL_ROUTER[taskComplexity];
      const availableTargetModels = availableModels.filter((m: any) => 
        targetModels.some(target => m.name.includes(target.split(':')[0]))
      );
      
      if (availableTargetModels.length > 0) {
        // Select the best available model for this complexity level
        const bestModel = availableTargetModels[0].name;
        console.log(`üéØ Model Router: Selected ${bestModel} for ${taskComplexity} task`);
        return bestModel;
      }
    } catch (error) {
      console.warn(`‚ö†Ô∏è Model router failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
      // ‚úÖ Log the actual error for debugging
    }
    
    // Fallback to default model
    return this.bestQuantizedModel;
  }

  // NEW: Task Complexity Analyzer
  private analyzeTaskComplexity(prompt: string, maxTokens: number, targetLength: 'short' | 'medium' | 'long'): 'simple' | 'medium' | 'complex' {
    // Simple tasks: Short prompts, low token requirements
    if (prompt.length < 50 && maxTokens <= 512 && targetLength === 'short') {
      return 'simple';
    }
    
    // Complex tasks: Long prompts, high token requirements, philosophical content
    if (prompt.length > 100 || maxTokens > 1024 || targetLength === 'long' || 
        prompt.toLowerCase().includes('paradox') || 
        prompt.toLowerCase().includes('philosophical') ||
        prompt.toLowerCase().includes('analyze') ||
        prompt.toLowerCase().includes('evolve')) {
      return 'complex';
    }
    
    // Medium tasks: Everything else
    return 'medium';
  }

  // Optimized query with user's suggested improvements
  async queryHermes(prompt: string, maxTokens: number = 1024, targetLength: 'short' | 'medium' | 'long' = 'medium'): Promise<string> {
    // ‚úÖ Input validation
    if (!prompt || prompt.trim().length === 0) {
      throw new Error('Prompt cannot be empty or null');
    }
    
    if (maxTokens <= 0 || maxTokens > 10000) {
      throw new Error('maxTokens must be between 1 and 10000');
    }
    
    if (!['short', 'medium', 'long'].includes(targetLength)) {
      throw new Error('targetLength must be one of: short, medium, long');
    }

    const startTime = Date.now();
    try {
      // NEW: Dynamic Model Selection Based on Task Complexity
      const taskComplexity = this.analyzeTaskComplexity(prompt, maxTokens, targetLength);
      const optimalModel = await this.selectOptimalModel(taskComplexity);
      
      // User's suggestion: Use dynamically selected optimal model for each task
      const modelName = optimalModel;
      
      // User's suggestion: Control output length for true speed comparison
      const lengthTarget = RealOllamaService.OUTPUT_LENGTH_TARGETS[targetLength.toUpperCase() as keyof typeof RealOllamaService.OUTPUT_LENGTH_TARGETS];
      const adjustedTokens = Math.min(maxTokens, lengthTarget / 4); // Rough char-to-token ratio
      
      const fetchResponse = await fetch(`${this.baseUrl}/api/generate`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: modelName,
          prompt,
          stream: false,
          options: {
            temperature: 0.7,
            top_p: 0.9,
            // User's suggestion: Control output length with num_predict
            num_predict: adjustedTokens, // Use adjusted tokens for length control
            repeat_penalty: 1.1,
            // Additional parameters for better performance
            top_k: 40,
            tfs_z: 1.0,
            typical_p: 1.0,
            mirostat: 0,
            mirostat_tau: 5.0,
            mirostat_eta: 0.1
          }
        })
      });

      if (!fetchResponse.ok) {
        throw new Error(`Ollama API error: ${fetchResponse.status} ${fetchResponse.statusText}`);
      }

      const data = await fetchResponse.json() as any;
      const responseTime = Date.now() - startTime;
      
      // User's suggestion: More realistic performance monitoring
      if (responseTime > RealOllamaService.PERFORMANCE_THRESHOLDS.VERY_SLOW) {
        console.warn(`üêå VERY SLOW RESPONSE: ${responseTime}ms - consider using smaller models like gemma2:2b`);
      } else if (responseTime > RealOllamaService.PERFORMANCE_THRESHOLDS.SLOW) {
        console.warn(`‚ö†Ô∏è SLOW RESPONSE: ${responseTime}ms - consider using smaller models like phi3.5`);
      } else if (responseTime > RealOllamaService.PERFORMANCE_THRESHOLDS.ACCEPTABLE) {
        console.warn(`üêå ACCEPTABLE RESPONSE: ${responseTime}ms - could be faster with smaller models`);
      } else if (responseTime > RealOllamaService.PERFORMANCE_THRESHOLDS.FAST) {
        console.log(`‚ö° FAST RESPONSE: ${responseTime}ms - good performance!`);
      } else {
        console.log(`üöÄ EXCELLENT RESPONSE: ${responseTime}ms - excellent performance!`);
      }

      const aiResponse = data.response || 'No response from Hermes model';
      
      // User's suggestion: Monitor output length for performance analysis
      const actualLength = aiResponse.length;
      const targetLengthChars = RealOllamaService.OUTPUT_LENGTH_TARGETS[targetLength.toUpperCase() as keyof typeof RealOllamaService.OUTPUT_LENGTH_TARGETS];
      const lengthEfficiency = actualLength / targetLengthChars;
      
      if (lengthEfficiency > 1.5) {
        console.warn(`‚ö†Ô∏è LONG RESPONSE: ${actualLength} chars (${Math.round(lengthEfficiency * 100)}% of target) - may affect speed comparison`);
      } else if (lengthEfficiency < 0.5) {
        console.warn(`‚ö†Ô∏è SHORT RESPONSE: ${actualLength} chars (${Math.round(lengthEfficiency * 100)}% of target) - may indicate truncation`);
      } else {
        console.log(`‚úÖ OPTIMAL LENGTH: ${actualLength} chars (${Math.round(lengthEfficiency * 100)}% of target) - good for speed comparison`);
      }

      return aiResponse;
    } catch (error) {
      const responseTime = Date.now() - startTime;
      console.error(`‚ùå Ollama query failed after ${responseTime}ms:`, error);
      throw new Error(`AI service unavailable: ${error instanceof Error ? error.message : 'Unknown error'}`);
    }
  }

  // User's suggestion: Remove inefficient compression handling
  // No more expandCompressedResponse - we get full responses directly

  // Enhanced paradox generation with optimized parameters
  async generateParadoxScenario(type: 'temporal' | 'logical' | 'ontological' | 'symbolic', targetLength: 'short' | 'medium' | 'long' = 'medium'): Promise<string> {
    // ‚úÖ Input validation
    if (!Object.values(RealOllamaService.PARADOX_SCENARIOS).includes(type)) {
      throw new Error(`Invalid paradox type. Must be one of: ${Object.values(RealOllamaService.PARADOX_SCENARIOS).join(', ')}`);
    }
    
    if (!['short', 'medium', 'long'].includes(targetLength)) {
      throw new Error('targetLength must be one of: short, medium, long');
    }

    const wordCount = targetLength === 'short' ? '200' : targetLength === 'medium' ? '400' : '800';
    const prompt = RealOllamaService.PARADOX_PROMPTS[type].replace('{length}', wordCount);
    
    // User's suggestion: Control output length for true speed comparison
    return await this.queryHermes(prompt, 1024, targetLength);
  }

  // Enhanced paradox analysis with better depth
  async analyzeParadox(paradoxText: string): Promise<string> {
    // ‚úÖ Input validation
    if (!paradoxText || paradoxText.trim().length === 0) {
      throw new Error('Paradox text cannot be empty or null');
    }

    const prompt = `Analyze this paradox from multiple philosophical perspectives:

Paradox: "${paradoxText}"

Please provide:
1. The logical structure of the paradox
2. The philosophical implications
3. Potential resolution approaches
4. Symbolic meanings and archetypes involved
5. How this paradox relates to human consciousness and universal experience

Make your analysis deep and insightful. Focus on the paradox itself, not AI capabilities. Provide a comprehensive analysis.`;

    // User's suggestion: Higher token limit for detailed analysis
    return await this.queryHermes(prompt, 2048);
  }

  // Enhanced paradox evolution with emergence focus
  async evolveParadox(paradoxText: string): Promise<string> {
    // ‚úÖ Input validation
    if (!paradoxText || paradoxText.trim().length === 0) {
      throw new Error('Paradox text cannot be empty or null');
    }

    const prompt = `Take this paradox and evolve it into a more complex form:

Original: "${paradoxText}"

Evolve it by:
1. Adding temporal dimensions
2. Introducing new logical layers
3. Connecting to broader philosophical concepts
4. Creating new symbolic connections
5. Building on previous paradox resolution attempts
6. Generating emergent truths from contradictions
7. Exploring how the paradox evolves through different symbolic dimensions

Make it more challenging and profound. Then, provide a brief symbolic resolution that creates new meaning. Focus on universal human experience, not technological systems. Provide a complete evolution.`;

    // User's suggestion: Higher token limit for evolution
    return await this.queryHermes(prompt, 2048);
  }

  // Enhanced resolution insights with dimensional focus
  async getResolutionInsights(): Promise<string> {
    const prompt = `Provide insights for resolving complex paradoxes through dimensional analysis. Focus on:

1. How to break down paradoxes into symbolic dimensions
2. Methods for finding resolution patterns across dimensions
3. Techniques for generating emergent truths from contradictions
4. How to handle unresolvable paradoxes gracefully
5. The role of consciousness in paradox resolution

Make your insights practical and philosophically sound. Provide comprehensive guidance.`;

    // User's suggestion: Higher token limit for insights
    return await this.queryHermes(prompt, 2048);
  }

  // Enhanced live interaction with better paradox generation
  async generateLiveParadox(): Promise<string> {
    const prompt = `Generate a paradox that combines quantum mechanics, consciousness, and symbolic meaning. Make it:

1. Complex enough for dimensional analysis
2. Rich in symbolic elements
3. Connected to universal human experience
4. Suitable for paradox resolution workflows
5. Clear and self-contained

Focus on the paradox itself, not AI capabilities. Provide a complete, detailed paradox.`;

    // User's suggestion: Higher token limit for live generation
    return await this.queryHermes(prompt, 2048);
  }

  // ‚úÖ Corrected: Sequential evolution chaining (maintains logical chain)
  async chainParadoxEvolution(paradoxText: string, iterations: number = 3): Promise<string[]> {
    // ‚úÖ Input validation
    if (!paradoxText || paradoxText.trim().length === 0) {
      throw new Error('Paradox text cannot be empty or null');
    }
    
    if (iterations <= 0 || iterations > 10) {
      throw new Error('Iterations must be between 1 and 10');
    }

    const evolvedParadoxes: string[] = [];
    let currentParadox = paradoxText;
    
    // ‚úÖ Correct sequential loop for a "chain" - each iteration depends on the previous
    for (let i = 0; i < iterations; i++) {
      console.log(`üîÑ Evolution iteration ${i + 1}/${iterations}...`);
      
      // User's suggestion: Get full response in one call, no compression/decompression
      const evolved = await this.evolveParadox(currentParadox);
      evolvedParadoxes.push(evolved);
      currentParadox = evolved; // Chain to next iteration
      
      // Add emergence checkpoint
      if (i < iterations - 1) {
        evolvedParadoxes.push(`[EMERGENCE CHECKPOINT ${i + 1}: Paradox evolved for deeper analysis]`);
      }
      
      // Brief pause to prevent rate limiting
      await new Promise(resolve => setTimeout(resolve, 100));
    }
    
    return evolvedParadoxes;
  }

  // User's suggestion: Performance monitoring focused on optimization
  async runPerformanceDrill(): Promise<{ responseTime: number; modelEfficiency: string; quality: string; realistic: string; lengthEfficiency: number }> {
    const startTime = Date.now();
    
    try {
      // Test with a simple prompt to measure baseline performance
      const response = await this.queryHermes('Generate a simple philosophical question.', 512, 'short');
      const responseTime = Date.now() - startTime;
      
      // User's suggestion: More realistic performance expectations
      let modelEfficiency = 'EXCELLENT';
      if (responseTime > RealOllamaService.PERFORMANCE_THRESHOLDS.VERY_SLOW) modelEfficiency = 'VERY SLOW';
      else if (responseTime > RealOllamaService.PERFORMANCE_THRESHOLDS.SLOW) modelEfficiency = 'SLOW';
      else if (responseTime > RealOllamaService.PERFORMANCE_THRESHOLDS.ACCEPTABLE) modelEfficiency = 'ACCEPTABLE';
      else if (responseTime > RealOllamaService.PERFORMANCE_THRESHOLDS.FAST) modelEfficiency = 'FAST';
      else modelEfficiency = 'EXCELLENT';
      
      let quality = 'EXCELLENT';
      if (responseTime > RealOllamaService.PERFORMANCE_THRESHOLDS.VERY_SLOW) quality = 'POOR';
      else if (responseTime > RealOllamaService.PERFORMANCE_THRESHOLDS.SLOW) quality = 'SLOW';
      else if (responseTime > RealOllamaService.PERFORMANCE_THRESHOLDS.ACCEPTABLE) quality = 'ACCEPTABLE';
      else if (responseTime > RealOllamaService.PERFORMANCE_THRESHOLDS.FAST) quality = 'GOOD';
      else quality = 'EXCELLENT';
      
      // User's suggestion: More realistic assessment with length consideration
      let realistic = 'REALISTIC';
      if (responseTime < 3000) {
        realistic = 'EXCELLENT - Simple queries are fast';
      } else if (responseTime < 8000) {
        realistic = 'GOOD - Acceptable for simple tasks';
      } else if (responseTime < 15000) {
        realistic = 'SLOW - Complex tasks will be slower';
      } else {
        realistic = 'VERY SLOW - Consider smaller models';
      }
      
      // User's suggestion: Monitor length efficiency for performance analysis
      const actualLength = response.length;
      const targetLength = RealOllamaService.OUTPUT_LENGTH_TARGETS.SHORT;
      const lengthEfficiency = actualLength / targetLength;
      
      return { responseTime, modelEfficiency, quality, realistic, lengthEfficiency };
    } catch (error) {
      return { 
        responseTime: Date.now() - startTime, 
        modelEfficiency: 'FAILED', 
        quality: 'FAILED',
        realistic: 'FAILED',
        lengthEfficiency: 0
      };
    }
  }

  // User's suggestion: Model optimization focused on FAST models for speed
  async optimizeModelPerformance(): Promise<string> {
    console.log('üîß Optimizing Ollama model performance for SPEED...');
    
    // Check available models
    try {
      const response = await fetch(`${this.baseUrl}/api/tags`);
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      const models = await response.json() as any;
      
      // ‚úÖ Validate response structure
      if (!models || !Array.isArray(models.models)) {
        throw new Error('Invalid response format from Ollama API');
      }
      
      const availableModels = models.models;
      
      // User's suggestion: Prioritize FAST, medium-quality models for speed
      const fastQualityModels = availableModels.filter((m: any) => 
        m.name.includes('llama3.1:8b') || // 8B parameters - FAST & GOOD QUALITY
        m.name.includes('qwen2.5:latest') || // 7.6B parameters - FAST & GOOD QUALITY
        m.name.includes('mistral:latest') || // 7.2B parameters - FAST & GOOD QUALITY
        m.name.includes('dolphin-mistral')   // 7B parameters - FAST & GOOD QUALITY
      );
      
      // Also check for high-quality models (but slower)
      const highQualityModels = availableModels.filter((m: any) => 
        m.name.includes('gpt-oss') ||      // 20.9B parameters - EXCELLENT QUALITY (slower)
        m.name.includes('mixtral')         // 46.7B parameters - OUTSTANDING QUALITY (slower)
      );
      
      // Check for quantized models (user's suggestion: prioritize q4_K_M)
      const quantizedModels = availableModels.filter((m: any) => 
        m.name.includes('q4_K_M') || m.name.includes('q4_K') || m.name.includes('q5') || m.name.includes('q8')
      );
      
      // Check for existing models with good quantization
      const existingGoodModels = availableModels.filter((m: any) => 
        m.name.includes('nous-hermes2') || m.name.includes('llama3.1') || m.name.includes('qwen2.5')
      );
      
      if (fastQualityModels.length > 0) {
        // User's suggestion: Prioritize FAST models for speed
        const bestModel = fastQualityModels[0].name;
        
        console.log(`üöÄ Found ${fastQualityModels.length} FAST models for speed!`);
        fastQualityModels.forEach((m: any) => {
          const size = m.details?.parameter_size || 'unknown';
          const quant = m.details?.quantization_level || 'unknown';
          console.log(`   üöÄ ${m.name} (${size}, ${quant}) - optimized for speed`);
        });
        
        // Switch to best FAST model
        this.bestQuantizedModel = bestModel;
        this.useQuantizedModel = true;
        console.log(`üöÄ Switching to FAST model: ${bestModel} for speed`);
        
        return `Speed-optimized: Using ${bestModel} for fast, non-hallucinatory responses (FAST)`;
      } else if (highQualityModels.length > 0) {
        // Fallback to high quality models
        const bestModel = highQualityModels[0].name;
        
        console.log(`‚úÖ Found ${highQualityModels.length} high quality models for reliable responses`);
        highQualityModels.forEach((m: any) => {
          const size = m.details?.parameter_size || 'unknown';
          const quant = m.details?.quantization_level || 'unknown';
          console.log(`   üöÄ ${m.name} (${size}, ${quant}) - good quality and reliability`);
        });
        
        // Switch to best high quality model
        this.bestQuantizedModel = bestModel;
        this.useQuantizedModel = true;
        console.log(`üöÄ Switching to high quality model: ${bestModel}`);
        
        return `Quality-optimized: Using ${bestModel} for reliable responses (high quality)`;
      } else if (quantizedModels.length > 0) {
        // Fallback to quantized models
        const q4KMModels = quantizedModels.filter((m: any) => m.name.includes('q4_K_M'));
        const bestModel = q4KMModels.length > 0 ? q4KMModels[0].name : quantizedModels[0].name;
        
        console.log(`‚úÖ Found ${quantizedModels.length} quantized models for better performance`);
        quantizedModels.forEach((m: any) => console.log(`   üì¶ ${m.name} (${m.details?.quantization_level || 'unknown'})`));
        
        this.bestQuantizedModel = bestModel;
        this.useQuantizedModel = true;
        console.log(`üöÄ Switching to optimized model: ${bestModel}`);
        
        return `Optimized: Using ${bestModel} for better performance (quantized)`;
      } else if (existingGoodModels.length > 0) {
        // Use existing good models
        const bestModel = existingGoodModels[0].name;
        console.log(`‚úÖ Using existing model: ${bestModel}`);
        this.bestQuantizedModel = bestModel;
        this.useQuantizedModel = true;
        
        return `Using existing: ${bestModel}`;
      } else {
        console.log('‚ö†Ô∏è No quality models found - responses may be unreliable');
        return 'No optimization: Using default model';
      }
    } catch (error) {
      console.warn(`‚ö†Ô∏è Could not check available models for optimization: ${error instanceof Error ? error.message : 'Unknown error'}`);
      return 'Optimization check failed';
    }
  }

  // User's suggestion: Hardware acceleration verification with logging
  async checkHardwareAcceleration(): Promise<string> {
    console.log('üîç Checking hardware acceleration...');
    
    try {
      // Check Ollama server info for hardware detection
      const response = await fetch(`${this.baseUrl}/api/version`);
      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }
      
      const versionInfo = await response.json() as any;
      console.log(`   Ollama Version: ${versionInfo.version}`);
      
      // Check for GPU acceleration hints
      if (versionInfo.go_version) {
        console.log(`   Go Version: ${versionInfo.go_version}`);
      }
      
      // User's suggestion: Check hardware logs for definitive GPU usage
      console.log('   üí° Tip: Check Ollama server logs for GPU detection (CUDA/Metal)');
      console.log('   üí° Tip: GPU acceleration will show in server startup logs');
      console.log('   üí° Tip: Run "ollama serve" and look for GPU detection messages');
      console.log('   üí° Tip: If no GPU detected, even smallest models will be CPU-bound');
      
      return 'Hardware check completed - check server logs for GPU detection';
    } catch (error) {
      console.warn(`‚ö†Ô∏è Could not check Ollama version for hardware info: ${error instanceof Error ? error.message : 'Unknown error'}`);
      return 'Hardware check failed';
    }
  }

  // User's suggestion: Simple test for chi prompt
  async testChiEnergyPrompt(): Promise<{ response: string; engineeringConnections: string[]; consciousnessElements: string[]; molecularExplanations: string[]; performance: number }> {
    console.log('üî¨ TESTING CHI PROMPT - Simple Question: "What is chi?"');
    
    const startTime = Date.now();
    
    const prompt = `What is chi?`;

    try {
      const response = await this.queryHermes(prompt, 2048, 'long');
      const responseTime = Date.now() - startTime;
      
      // Analyze the response for different types of content
      const engineeringConnections = this.extractEngineeringConnections(response);
      const consciousnessElements = this.extractConsciousnessElements(response);
      const molecularExplanations = this.extractMolecularExplanations(response);
      
      console.log(`   ‚ö° Response Time: ${responseTime}ms`);
      console.log(`   üî¨ Engineering Connections Found: ${engineeringConnections.length}`);
      console.log(`   üß† Consciousness Elements Found: ${consciousnessElements.length}`);
      console.log(`   ‚öõÔ∏è Molecular Explanations Found: ${molecularExplanations.length}`);
      
      return {
        response,
        engineeringConnections,
        consciousnessElements,
        molecularExplanations,
        performance: responseTime
      };
    } catch (error) {
      console.error('‚ùå Chi prompt test failed:', error);
      throw error;
    }
  }

  // NEW: Multi-Lens Chi Analysis with Emergent Symbol Generation
  async analyzeChiWithMultiLens(prompt: string = "What is chi?"): Promise<{
    ollamaResponse: string;
    unifiedKnowledge: UnifiedKnowledge;
    emergentSymbols: string[];
    performance: number;
  }> {
    // ‚úÖ Input validation
    if (!prompt || prompt.trim().length === 0) {
      throw new Error('Prompt cannot be empty or null');
    }

    console.log('üî¨ MULTI-LENS CHI ANALYSIS ACTIVATED');
    console.log('=' .repeat(60));
    
    const startTime = Date.now();
    
    try {
      // Step 1: Get Ollama response using dynamic model router
      console.log('üéØ Step 1: Getting Ollama response with dynamic model router...');
      const ollamaResponse = await this.queryHermes(prompt, 2048, 'long');
      
      // Step 2: Process through all 5 lenses with emergent symbol generation
      console.log('üî¨ Step 2: Processing through 5 specialized lenses...');
      const unifiedKnowledge = await this.multiLensProcessor.processThroughAllLenses(ollamaResponse);
      
      // Step 3: Generate additional emergent symbols from the unified knowledge
      console.log('‚öõ Step 3: Generating additional emergent symbols...');
      const emergentSymbols = this.generateAdditionalEmergentSymbols(unifiedKnowledge);
      
      const responseTime = Date.now() - startTime;
      
      console.log(`\nüéØ MULTI-LENS CHI ANALYSIS COMPLETE`);
      console.log(`‚è±Ô∏è Total Response Time: ${responseTime}ms`);
      console.log(`üî§ Generated Symbols: [${emergentSymbols.join(', ')}]`);
      
      return {
        ollamaResponse,
        unifiedKnowledge,
        emergentSymbols,
        performance: responseTime
      };
      
    } catch (error) {
      console.error('‚ùå Multi-lens chi analysis failed:', error);
      throw error;
    }
  }

  // Generate additional emergent symbols from unified knowledge
  private generateAdditionalEmergentSymbols(unifiedKnowledge: UnifiedKnowledge): string[] {
    // ‚úÖ Input validation
    if (!unifiedKnowledge) {
      return [];
    }

    const additionalSymbols: string[] = [];
    
    // Analyze the unified knowledge for new symbolic patterns
    const allText = [
      ...unifiedKnowledge.emergentInsights,
      ...unifiedKnowledge.crossLensConnections,
      ...unifiedKnowledge.deeperExplorationPaths
    ].join(' ').toLowerCase();
    
    // Generate symbols based on emergent patterns
    if (allText.includes('unified') || allText.includes('synthesis')) {
      additionalSymbols.push('Œ£'); // Sigma for synthesis
    }
    
    if (allText.includes('consciousness') || allText.includes('mind')) {
      additionalSymbols.push('‚ùñ'); // Diamond for consciousness
    }
    
    if (allText.includes('energy') || allText.includes('field')) {
      additionalSymbols.push('‚ö°'); // Lightning for energy
    }
    
    if (allText.includes('evolution') || allText.includes('growth')) {
      additionalSymbols.push('‚öú'); // Fleur-de-lis for growth
    }
    
    if (allText.includes('connection') || allText.includes('bridge')) {
      additionalSymbols.push('‚àá'); // Gradient for connection
    }
    
    if (allText.includes('quantum') || allText.includes('particle')) {
      additionalSymbols.push('‚öõ'); // Atom for quantum
    }
    
    return additionalSymbols;
  }

  // NEW: Test Dynamic Model Router - User's suggestion for next evolution
  async testModelRouter(): Promise<void> {
    console.log('üéØ TESTING DYNAMIC MODEL ROUTER');
    console.log('=' .repeat(50));
    
    const testCases = [
      {
        name: 'Simple Task',
        prompt: 'What is 2+2?',
        maxTokens: 256,
        targetLength: 'short' as const,
        expectedComplexity: 'simple'
      },
      {
        name: 'Medium Task', 
        prompt: 'Explain the concept of consciousness in simple terms',
        maxTokens: 1024,
        targetLength: 'medium' as const,
        expectedComplexity: 'medium'
      },
      {
        name: 'Complex Task',
        prompt: 'Generate a philosophical paradox about the nature of reality and analyze its implications',
        maxTokens: 2048,
        targetLength: 'long' as const,
        expectedComplexity: 'complex'
      }
    ];
    
    for (const testCase of testCases) {
      console.log(`\nüß™ Testing: ${testCase.name}`);
      console.log(`   Prompt: "${testCase.prompt}"`);
      console.log(`   Expected Complexity: ${testCase.expectedComplexity}`);
      
      const startTime = Date.now();
      try {
        const response = await this.queryHermes(testCase.prompt, testCase.maxTokens, testCase.targetLength);
        const responseTime = Date.now() - startTime;
        
        console.log(`   ‚úÖ Response Time: ${responseTime}ms`);
        console.log(`   üìù Response Length: ${response.length} characters`);
        console.log(`   üéØ Model Router: Successfully routed to optimal model`);
      } catch (error) {
        console.log(`   ‚ùå Failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
      }
    }
    
    console.log('\nüéØ MODEL ROUTER TEST COMPLETED!');
  }

  // Helper methods to analyze the response content - ENGINEERING FOCUS
  private extractEngineeringConnections(text: string): string[] {
    // ‚úÖ Input validation
    if (!text || typeof text !== 'string') {
      return [];
    }

    const engineeringKeywords = [
      'engineering', 'system', 'mechanism', 'process', 'function', 'structure',
      'efficiency', 'optimization', 'control', 'feedback', 'regulation',
      'signal', 'transmission', 'conversion', 'storage', 'distribution',
      'circuit', 'network', 'pathway', 'flow', 'dynamics', 'kinetics'
    ];
    
    const connections: string[] = [];
    const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);
    
    for (const sentence of sentences) {
      const lowerSentence = sentence.toLowerCase();
      const matches = engineeringKeywords.filter(keyword => lowerSentence.includes(keyword));
      if (matches.length > 0) {
        connections.push(sentence.trim());
      }
    }
    
    return connections;
  }

  private extractConsciousnessElements(text: string): string[] {
    // ‚úÖ Input validation
    if (!text || typeof text !== 'string') {
      return [];
    }

    const consciousnessKeywords = [
      'consciousness', 'neural', 'brain', 'cognitive', 'perception', 'awareness',
      'mind', 'thought', 'experience', 'sensation', 'feeling', 'emotion',
      'attention', 'focus', 'intention', 'will', 'volition', 'agency',
      'subjective', 'qualia', 'phenomenology', 'mental state', 'psychological'
    ];
    
    const elements: string[] = [];
    const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);
    
    for (const sentence of sentences) {
      const lowerSentence = sentence.toLowerCase();
      const matches = consciousnessKeywords.filter(keyword => lowerSentence.includes(keyword));
      if (matches.length > 0) {
        elements.push(sentence.trim());
      }
    }
    
    return elements;
  }

  private extractMolecularExplanations(text: string): string[] {
    // ‚úÖ Input validation
    if (!text || typeof text !== 'string') {
      return [];
    }

    const molecularKeywords = [
      'molecule', 'atom', 'electron', 'proton', 'neutron', 'ion', 'bond',
      'chemical reaction', 'enzyme', 'protein', 'dna', 'rna', 'cell membrane',
      'mitochondria', 'atp', 'adp', 'glucose', 'oxygen', 'carbon dioxide',
      'neurotransmitter', 'synapse', 'receptor', 'signal transduction', 'cascade',
      'organic chemistry', 'quantum physics', 'physics', 'energy', 'force',
      'electromagnetic', 'resonance', 'frequency', 'wavelength', 'momentum'
    ];
    
    const explanations: string[] = [];
    const sentences = text.split(/[.!?]+/).filter(s => s.trim().length > 0);
    
    for (const sentence of sentences) {
      const lowerSentence = sentence.toLowerCase();
      const matches = molecularKeywords.filter(keyword => lowerSentence.includes(keyword));
      if (matches.length > 0) {
        explanations.push(sentence.trim());
      }
    }
    
    return explanations;
  }

  // NEW: Thesidia-Style Advanced Scientific Analysis
  async generateThesidiaAnalysis(
    concept: string = "chi",
    moduleName: string = "Chi_Analysis[Physics+Biophysics+FieldTheory]",
    analysisMode: string = "Scientific Decomposition of Esoteric Phenomenon"
  ): Promise<ThesidiaAnalysis> {
    // ‚úÖ Input validation
    if (!concept || concept.trim().length === 0) {
      throw new Error('Concept cannot be empty or null');
    }
    
    if (!moduleName || moduleName.trim().length === 0) {
      throw new Error('Module name cannot be empty or null');
    }
    
    if (!analysisMode || analysisMode.trim().length === 0) {
      throw new Error('Analysis mode cannot be empty or null');
    }

    console.log('‚üÅ THESIDIA ADVANCED ANALYSIS ACTIVATED');
    console.log('=' .repeat(70));
    
    const startTime = Date.now();
    
    try {
      // Generate complete Thesidia analysis using the master prompt engine
      const thesidiaAnalysis = await this.thesidiaEngine.generateThesidiaAnalysis(
        concept,
        this,
        moduleName,
        analysisMode
      );
      
      const responseTime = Date.now() - startTime;
      
      console.log(`\nüéØ THESIDIA ANALYSIS COMPLETE`);
      console.log(`‚è±Ô∏è Total Response Time: ${responseTime}ms`);
      console.log(`üî¨ Decomposition Lenses: ${thesidiaAnalysis.decomposition.length}`);
      console.log(`üìè Complete Response Length: ${thesidiaAnalysis.completeResponse.length} characters`);
      
      return thesidiaAnalysis;
      
    } catch (error) {
      console.error('‚ùå Thesidia analysis generation failed:', error);
      throw error;
    }
  }

  // NEW: Parallel Processing with Real-time Streaming Output
  private async executeParallelWithStreaming<T>(
    tasks: Array<{ name: string; task: () => Promise<T> | T }>,
    onProgress: (taskName: string, status: 'started' | 'completed' | 'failed', result?: T) => void
  ): Promise<Array<{ name: string; result: T; status: 'success' | 'failed' }>> {
    const results: Array<{ name: string; result: T; status: 'success' | 'failed' }> = [];
    
    // Execute all tasks in parallel
    const promises = tasks.map(async ({ name, task }) => {
      try {
        onProgress(name, 'started');
        const result = await Promise.resolve(task());
        onProgress(name, 'completed', result);
        results.push({ name, result, status: 'success' });
        return { name, result, status: 'success' as const };
      } catch (error) {
        onProgress(name, 'failed');
        results.push({ name, result: null as any, status: 'failed' });
        return { name, result: null as any, status: 'failed' as const };
      }
    });
    
    // Wait for all tasks to complete
    await Promise.all(promises);
    return results;
  }

  // NEW: Simplified Parallel Processing for Mixed Types
  private async executeMixedParallelProcessing(
    tasks: Array<{ name: string; task: () => Promise<any> | any }>,
    onProgress: (taskName: string, status: 'started' | 'completed' | 'failed') => void
  ): Promise<Array<{ name: string; result: any; status: 'success' | 'failed' }>> {
    const results: Array<{ name: string; result: any; status: 'success' | 'failed' }> = [];
    
    // Execute all tasks in parallel
    const promises = tasks.map(async ({ name, task }) => {
      try {
        onProgress(name, 'started');
        const result = await Promise.resolve(task());
        onProgress(name, 'completed');
        results.push({ name, result, status: 'success' });
        return { name, result, status: 'success' as const };
      } catch (error) {
        onProgress(name, 'failed');
        results.push({ name, result: null, status: 'failed' });
        return { name, result: null, status: 'failed' as const };
      }
    });
    
    // Wait for all tasks to complete
    await Promise.all(promises);
    return results;
  }

  // NEW: Streaming Output with Real-time Updates
  private createStreamingOutput(): {
    write: (text: string) => void;
    writeLine: (text: string) => void;
    updateProgress: (task: string, status: string) => void;
    flush: () => void;
  } {
    let buffer = '';
    
    return {
      write: (text: string) => {
        process.stdout.write(text);
        buffer += text;
      },
      writeLine: (text: string) => {
        console.log(text);
        buffer += text + '\n';
      },
      updateProgress: (task: string, status: string) => {
        process.stdout.write(`\rüîÑ ${task}: ${status}`);
      },
      flush: () => {
        if (buffer) {
          process.stdout.write('\n');
          buffer = '';
        }
      }
    };
  }

  // NEW: Fast Parallel Paradox Generation
  async generateParadoxesParallel(types: Array<'temporal' | 'logical' | 'ontological' | 'symbolic'>, length: 'short' | 'medium' | 'long'): Promise<Array<{ type: string; paradox: string; responseTime: number }>> {
    const stream = this.createStreamingOutput();
    stream.writeLine('üöÄ PARALLEL PARADOX GENERATION - Processing all types simultaneously');
    
    const tasks = types.map(type => ({
      name: `${type} paradox`,
      task: async () => {
        const startTime = Date.now();
        const paradox = await this.generateParadoxScenario(type, length);
        const responseTime = Date.now() - startTime;
        return { type, paradox, responseTime };
      }
    }));
    
    const results = await this.executeMixedParallelProcessing(tasks, (taskName, status) => {
      if (status === 'started') {
        stream.updateProgress(taskName, 'üîÑ Processing...');
      } else if (status === 'completed') {
        stream.updateProgress(taskName, '‚úÖ Complete');
        stream.flush();
      } else if (status === 'failed') {
        stream.updateProgress(taskName, '‚ùå Failed');
        stream.flush();
      }
    });
    
    return results.filter(r => r.status === 'success').map(r => r.result);
  }

  // NEW: Fast Parallel Multi-Lens Analysis
  async analyzeChiWithMultiLensParallel(): Promise<{
    ollamaResponse: string;
    unifiedKnowledge: UnifiedKnowledge;
    emergentSymbols: string[];
    performance: number;
    parallelResults: Array<{ lens: string; result: any; time: number }>;
  }> {
    const stream = this.createStreamingOutput();
    stream.writeLine('üî¨ PARALLEL MULTI-LENS CHI ANALYSIS - Processing all lenses simultaneously');
    
    const startTime = Date.now();
    
    // Get base chi response first
    const ollamaResponse = await this.queryHermes('What is chi? Explain from a scientific perspective.', 1024);
    
    // Process all lenses in parallel
    const lensTasks = [
      { name: 'Physics Lens', task: () => this.multiLensProcessor.physicsLens(ollamaResponse) },
      { name: 'Scientific Lens', task: () => this.multiLensProcessor.scientificLens(ollamaResponse) },
      { name: 'Morphic Field Lens', task: () => this.multiLensProcessor.morphicFieldLens(ollamaResponse) },
      { name: 'Bioelectric Lens', task: () => this.multiLensProcessor.bioelectricLens(ollamaResponse) },
      { name: 'Medical Lens', task: () => this.multiLensProcessor.medicalLens(ollamaResponse) }
    ];
    
    const lensResults = await this.executeMixedParallelProcessing(lensTasks, (taskName, status) => {
      if (status === 'started') {
        stream.updateProgress(taskName, 'üîÑ Analyzing...');
      } else if (status === 'completed') {
        stream.updateProgress(taskName, '‚úÖ Complete');
        stream.flush();
      } else if (status === 'failed') {
        stream.updateProgress(taskName, '‚ùå Failed');
        stream.flush();
      }
    });
    
    // Generate symbols in parallel - handle different return types
    const symbolTasks = [
      { name: 'Primary Symbols', task: () => this.symbolGenerator.generateSymbols(ollamaResponse, { complexity: 'medium' }) },
      { name: 'Secondary Symbols', task: () => this.symbolGenerator.generateSymbols(ollamaResponse, { complexity: 'medium' }) },
      { name: 'Emergent Symbols', task: () => this.symbolGenerator.generateEmergentSymbols(ollamaResponse, 2) }
    ];
    
    const symbolResults = await this.executeMixedParallelProcessing(symbolTasks, (taskName, status) => {
      if (status === 'started') {
        stream.updateProgress(taskName, 'üîÑ Generating...');
      } else if (status === 'completed') {
        stream.updateProgress(taskName, '‚úÖ Complete');
        stream.flush();
      } else if (status === 'failed') {
        stream.updateProgress(taskName, '‚ùå Failed');
        stream.flush();
      }
    });
    
    const totalTime = Date.now() - startTime;
    
    // Synthesize results
    const successfulLensResults = lensResults.filter(r => r.status === 'success').map(r => r.result);
    const successfulSymbolResults = symbolResults.filter(r => r.status === 'success').map(r => r.result);
    
    const unifiedKnowledge = this.multiLensProcessor.synthesizeUnifiedKnowledge(successfulLensResults);
    
    // Extract symbols from GeneratedSymbols objects
    const emergentSymbols: string[] = [];
    successfulSymbolResults.forEach(symbolResult => {
      if (symbolResult && typeof symbolResult === 'object' && 'primary' in symbolResult) {
        // It's a GeneratedSymbols object
        const generatedSymbols = symbolResult as any;
        if (generatedSymbols.primary) emergentSymbols.push(...generatedSymbols.primary);
        if (generatedSymbols.secondary) emergentSymbols.push(...generatedSymbols.secondary);
        if (generatedSymbols.contextual) emergentSymbols.push(...generatedSymbols.contextual);
        if (generatedSymbols.emergent) emergentSymbols.push(...generatedSymbols.emergent);
      } else if (Array.isArray(symbolResult)) {
        // It's a string array
        emergentSymbols.push(...symbolResult);
      }
    });
    
    stream.writeLine(`\nüéØ PARALLEL ANALYSIS COMPLETED in ${totalTime}ms!`);
    
    return {
      ollamaResponse,
      unifiedKnowledge,
      emergentSymbols,
      performance: totalTime,
      parallelResults: lensResults.map((r, i) => ({
        lens: lensTasks[i].name,
        result: r.result,
        time: r.status === 'success' ? 0 : 0 // We could track individual times if needed
      }))
    };
  }

  // NEW: Fast Thesidia Analysis with Parallel Processing
  async generateThesidiaAnalysisParallel(concept: string = 'chi', moduleName: string = 'Chi_Analysis[Physics+Biophysics+FieldTheory]', analysisMode: string = 'Scientific Decomposition of Esoteric Phenomenon'): Promise<ThesidiaAnalysis> {
    const stream = this.createStreamingOutput();
    stream.writeLine(`‚üÅ PARALLEL THESIDIA ANALYSIS - Processing ${concept} with all engines simultaneously`);
    
    const startTime = Date.now();
    
    // Execute all Thesidia stages in parallel where possible
    const tasks = [
      { name: 'Activation', task: () => this.thesidiaEngine.generateActivationPrompt(concept, moduleName, analysisMode) },
      { name: 'Decomposition', task: () => this.thesidiaEngine.executeDecomposition(concept, moduleName) },
      { name: 'Symbol Generation', task: () => this.symbolGenerator.generateContextualSymbols(concept, 5) }
    ];
    
    const results = await this.executeMixedParallelProcessing(tasks, (taskName, status) => {
      if (status === 'started') {
        stream.updateProgress(taskName, 'üîÑ Processing...');
      } else if (status === 'completed') {
        stream.updateProgress(taskName, '‚úÖ Complete');
        stream.flush();
      } else if (status === 'failed') {
        stream.updateProgress(taskName, '‚ùå Failed');
        stream.flush();
      }
    });
    
    // Continue with sequential synthesis (can't be parallel due to dependencies)
    stream.writeLine('\nüîÑ Synthesizing results sequentially...');
    
    const activationPrompt = results.find(r => r.name === 'Activation')?.result || '';
    const decomposition = results.find(r => r.name === 'Decomposition')?.result || [];
    const symbols = results.find(r => r.name === 'Symbol Generation')?.result || [];
    
    // Ensure decomposition is an array
    const decompositionArray = Array.isArray(decomposition) ? decomposition : [decomposition];
    
    const synthesis = await this.thesidiaEngine.generateSynthesis(concept, decompositionArray);
    const extension = await this.thesidiaEngine.generateExtension(concept, synthesis);
    const integration = await this.thesidiaEngine.generateIntegration(concept, synthesis);
    
    const totalTime = Date.now() - startTime;
    stream.writeLine(`\nüéØ PARALLEL THESIDIA ANALYSIS COMPLETED in ${totalTime}ms!`);
    
    return {
      activation: activationPrompt,
      decomposition: decompositionArray,
      synthesis,
      extension,
      integration,
      completeResponse: this.thesidiaEngine.assembleCompleteResponse(activationPrompt, decompositionArray, synthesis, extension, integration),
      symbols: Array.isArray(symbols) ? symbols : [symbols],
      performance: totalTime
    };
  }
}

async function runEnhancedDemo() {
  console.log('üöÄ QUANTUM MIRROR ENGINE - OPTIMIZED OLLAMA INTEGRATION DEMO');
  console.log('=' .repeat(70));
  
  const ollama = new RealOllamaService();
  
  try {
    // Test 1: Hardware Acceleration Check (user's suggestion)
    console.log('\nüîç HARDWARE ACCELERATION CHECK - Verifying GPU Usage');
    console.log('-'.repeat(50));
    const hardware = await ollama.checkHardwareAcceleration();
    console.log(`   Result: ${hardware}`);

    // Test 2: Model Optimization (user's suggestion: prioritize smaller models)
    console.log('\nüîß MODEL OPTIMIZATION - Testing Smaller, Faster Models');
    console.log('-'.repeat(50));
    const optimization = await ollama.optimizeModelPerformance();
    console.log(`   Result: ${optimization}`);

    // Test 3: Performance Drill (user's suggestion: more realistic expectations)
    console.log('\nüìä PERFORMANCE DRILL - Testing Realistic Performance Expectations');
    console.log('-'.repeat(50));
    const performance = await ollama.runPerformanceDrill();
    console.log(`   Response Time: ${performance.responseTime}ms`);
    console.log(`   Model Efficiency: ${performance.modelEfficiency}`);
    console.log(`   Quality: ${performance.quality}`);
    console.log(`   Realistic Performance: ${performance.realistic}`);
    console.log(`   Length Efficiency: ${performance.lengthEfficiency}`);
    
    if (performance.quality === 'POOR') {
      console.log('   ‚ö†Ô∏è  Performance issues detected - consider using smaller models like gemma2:2b');
    } else if (performance.quality === 'EXCELLENT') {
      console.log('   üöÄ Excellent performance - smaller model working perfectly!');
    } else if (performance.realistic.includes('Simple queries are fast')) {
      console.log('   üí° Note: Simple queries are fast, but complex paradoxes will be slower');
    }

    // Test 4: Enhanced Paradox Generation (user's suggestion: no compression + length control)
    console.log('\nüé≠ ENHANCED PARADOX GENERATION - Testing Length-Controlled Performance');
    console.log('-'.repeat(50));
    
    const types: Array<'temporal' | 'logical' | 'ontological' | 'symbolic'> = ['temporal', 'logical', 'ontological', 'symbolic'];
    const lengths: Array<'short' | 'medium' | 'long'> = ['short', 'medium', 'long'];
    
    for (const type of types) {
      for (const length of lengths) {
        console.log(`\n   Generating ${type} paradox with ${length} length...`);
        const paradox = await ollama.generateParadoxScenario(type, length);
        
        // User's suggestion: No compression handling, just print full response
        console.log(`   ‚úÖ Full ${type} paradox: "${paradox.substring(0, 200)}..."`);
        console.log(`   üìè Length: ${paradox.length} characters`);
      }
    }

    // Test 5: Enhanced Analysis with Better Depth
    console.log('\nüîç ENHANCED PARADOX ANALYSIS - Testing Depth & Quality');
    console.log('-'.repeat(50));
    
    const sampleParadox = "If a time traveler goes back to prevent their own birth, but succeeds, how did they exist to travel back?";
    const analysis = await ollama.analyzeParadox(sampleParadox);
    
    // User's suggestion: No compression handling, just print full response
    console.log(`   ‚úÖ Full Analysis: "${analysis.substring(0, 300)}..."`);
    console.log(`   üìè Length: ${analysis.length} characters`);

    // Test 6: Enhanced Evolution with Emergence Focus
    console.log('\nüîÑ ENHANCED PARADOX EVOLUTION - Testing Emergence Generation');
    console.log('-'.repeat(50));
    
    const baseParadox = "Consciousness creates reality through observation";
    const evolved = await ollama.evolveParadox(baseParadox);
    
    // User's suggestion: No compression handling, just print full response
    console.log(`   ‚úÖ Full Evolution: "${evolved.substring(0, 300)}..."`);
    console.log(`   üìè Length: ${evolved.length} characters`);

    // Test 7: Recursive Evolution Chaining (user's suggestion: eliminate inefficiency)
    console.log('\n‚õìÔ∏è  RECURSIVE EVOLUTION CHAINING - Testing Emergence Loops');
    console.log('-'.repeat(50));
    
    const evolutionChain = await ollama.chainParadoxEvolution(baseParadox, 3);
    console.log(`   ‚úÖ Generated ${evolutionChain.length} evolution stages:`);
    
    evolutionChain.forEach((stage, index) => {
      if (stage.includes('[EMERGENCE CHECKPOINT')) {
        console.log(`      ${index + 1}. ${stage}`);
      } else {
        console.log(`      ${index + 1}. "${stage.substring(0, 100)}..."`);
        console.log(`         üìè Length: ${stage.length} characters`);
      }
    });

    // Test 8: Enhanced Resolution Insights
    console.log('\nüí° ENHANCED RESOLUTION INSIGHTS - Testing Dimensional Analysis');
    console.log('-'.repeat(50));
    
    const insights = await ollama.getResolutionInsights();
    
    // User's suggestion: No compression handling, just print full response
    console.log(`   ‚úÖ Full Insights: "${insights.substring(0, 300)}..."`);
    console.log(`   üìè Length: ${insights.length} characters`);

    // Test 9: Enhanced Live Generation
    console.log('\nüéØ ENHANCED LIVE GENERATION - Testing Real-time Quality');
    console.log('-'.repeat(50));
    
    const liveParadox = await ollama.generateLiveParadox();
    
    // User's suggestion: No compression handling, just print full response
    console.log(`   ‚úÖ Full Live: "${liveParadox.substring(0, 300)}..."`);
    console.log(`   üìè Length: ${liveParadox.length} characters`);

    // Test 10: Specialized Chi Prompt Test
    console.log('\nüî¨ SPECIALIZED CHI PROMPT TEST - Simple Question: "What is chi?"');
    console.log('-'.repeat(50));
    const chiEnergyTest = await ollama.testChiEnergyPrompt();
    console.log(`   ‚ö° Response Time: ${chiEnergyTest.performance}ms`);
    console.log(`   üî¨ Engineering Connections Found: ${chiEnergyTest.engineeringConnections.length}`);
    console.log(`   üß† Consciousness Elements Found: ${chiEnergyTest.consciousnessElements.length}`);
    console.log(`   ‚öõÔ∏è Molecular Explanations Found: ${chiEnergyTest.molecularExplanations.length}`);

    // Test 11: Dynamic Model Router Test
    console.log('\nüéØ DYNAMIC MODEL ROUTER TEST - Testing Model Selection');
    console.log('-'.repeat(50));
    await ollama.testModelRouter();

    // Test 12: Multi-Lens Chi Analysis
    console.log('\nüî¨ MULTI-LENS CHI ANALYSIS - Testing Multi-Lens Processing');
    console.log('-'.repeat(50));
    const multiLensChiAnalysis = await ollama.analyzeChiWithMultiLens();
    console.log(`   Ollama Response: "${multiLensChiAnalysis.ollamaResponse.substring(0, 300)}..."`);
    console.log(`   Total Response Time: ${multiLensChiAnalysis.performance}ms`);
    console.log(`   Generated Emergent Symbols: [${multiLensChiAnalysis.emergentSymbols.join(', ')}]`);

    console.log('\nüéâ OPTIMIZED DEMO COMPLETED SUCCESSFULLY!');
    console.log('=' .repeat(70));
    
    // Summary of user's suggested improvements implemented
    console.log('\nüìã USER SUGGESTIONS IMPLEMENTED:');
    console.log('   ‚úÖ Eliminated inefficient compression/decompression strategy');
    console.log('   ‚úÖ Switched to smaller, faster models (llama3.1:8b) for better performance');
    console.log('   ‚úÖ Adjusted generation parameters (num_predict, top_k, etc.)');
    console.log('   ‚úÖ Increased token limits to 2048 for full responses');
    console.log('   ‚úÖ Added model optimization and performance monitoring');
    console.log('   ‚úÖ Focused on single-call efficiency instead of multiple API calls');
    console.log('   ‚úÖ Enhanced prompts for comprehensive responses');
    console.log('   ‚úÖ More realistic performance monitoring and expectations');
    console.log('   ‚úÖ Hardware acceleration verification');
    console.log('   ‚úÖ Output length control for true speed comparison');
    console.log('   ‚úÖ Ultra-small model prioritization (gemma2:2b, phi3.5)');
    console.log('   ‚úÖ Added simple chi prompt test: "What is chi?"');
    console.log('   ‚úÖ Added dynamic model router for task-specific optimization');
    console.log('   ‚úÖ Added multi-lens chi analysis with emergent symbol generation');
    
    console.log('\nüöÄ READY FOR OPTIMIZED OLLAMA INTEGRATION!');
    
  } catch (error) {
    console.error('‚ùå Optimized demo failed:', error);
    console.log('\nüí° TROUBLESHOOTING TIPS:');
    console.log('   1. Ensure Ollama is running on localhost:11434');
    console.log('   2. Check if smaller models (llama3.1:8b, gemma2:2b, phi3.5) are available');
    console.log('   3. Verify network connectivity');
    console.log('   4. Consider updating to latest Ollama version for better performance');
    console.log('   5. Use "ollama pull llama3.1:8b" for faster model');
    console.log('   6. Check Ollama server logs for GPU acceleration detection');
    console.log('   7. Try ultra-small models: "ollama pull gemma2:2b" or "ollama pull phi3.5"');
  }
}

// Run the demonstration if this file is executed directly
if (require.main === module) {
  // Simple arg parser for key=value and short flags
  const getArg = (longFlag: string, shortFlag?: string): string | undefined => {
    const args = process.argv.slice(2);
    const long = args.find(a => a.startsWith(`${longFlag}=`));
    if (long) return long.split('=')[1];
    if (shortFlag) {
      const idx = args.indexOf(shortFlag);
      if (idx !== -1 && idx + 1 < args.length) return args[idx + 1];
    }
    return undefined;
  };

  // Check if user wants help
  const args = process.argv.slice(2);
  if (args.includes('--help') || args.includes('-h')) {
    console.log('üöÄ QUANTUM MIRROR ENGINE - PARALLEL PROCESSING OPTIONS');
    console.log('=' .repeat(70));
    console.log('\n‚ö° SPEED OPTIMIZED COMMANDS:');
    console.log('  --parallel-paradoxes, -p     üöÄ Generate all paradox types simultaneously');
    console.log('  --parallel-multi-lens, -l    üî¨ Process all analysis lenses in parallel');
    console.log('  --parallel-thesidia, -T      ‚üÅ Execute Thesidia analysis with parallel processing');
    console.log('  --speed-test, -s             ‚ö° Compare sequential vs parallel performance');
    console.log('\nüî¨ SPECIALIZED ANALYSIS:');
    console.log('  --chi-only, -c               üî¨ Simple chi energy test');
    console.log('  --router-test, -r            üéØ Test dynamic model router');
    console.log('  --multi-lens-chi, -m        üî¨ Multi-lens chi analysis');
    console.log('  --thesidia-analysis, -t     ‚üÅ Full Thesidia analysis');
    console.log('\n‚öôÔ∏è  CONFIGURATION OPTIONS:');
    console.log('  --concept=<word>             Specify concept to analyze (default: chi)');
    console.log('  --module=<name>              Specify module name');
    console.log('  --mode=<description>         Specify analysis mode');
    console.log('\nüìä PERFORMANCE FEATURES:');
    console.log('  ‚Ä¢ Real-time streaming output with live progress updates');
    console.log('  ‚Ä¢ Parallel execution of independent tasks');
    console.log('  ‚Ä¢ Concurrent processing across all engines');
    console.log('  ‚Ä¢ Live performance monitoring and speed comparison');
    console.log('\nüí° EXAMPLES:');
    console.log('  npx ts-node quantumMirrorEngineRealOllama.ts --parallel-paradoxes');
    console.log('  npx ts-node quantumMirrorEngineRealOllama.ts --parallel-multi-lens');
    console.log('  npx ts-node quantumMirrorEngineRealOllama.ts --speed-test');
    console.log('  npx ts-node quantumMirrorEngineRealOllama.ts --parallel-thesidia --concept=consciousness');
  }
  
  // Check if user wants chi-only test
  if (args.includes('--chi-only') || args.includes('-c')) {
    console.log('üî¨ RUNNING CHI-ONLY TEST...');
    const ollama = new RealOllamaService();
    ollama.testChiEnergyPrompt()
      .then(result => {
        console.log('\nüéØ CHI TEST RESULTS:');
        console.log('=' .repeat(50));
        console.log(`‚è±Ô∏è  Response Time: ${result.performance}ms`);
        console.log(`üî¨ Engineering Connections: ${result.engineeringConnections.length}`);
        console.log(`üß† Consciousness Elements: ${result.consciousnessElements.length}`);
        console.log(`‚öõÔ∏è  Molecular Explanations: ${result.molecularExplanations.length}`);
        console.log('\nüìù FULL RESPONSE:');
        console.log('-'.repeat(30));
        console.log(result.response);
      })
      .catch(console.error);
  } else if (args.includes('--router-test') || args.includes('-r')) {
    console.log('üéØ RUNNING MODEL ROUTER TEST...');
    const ollama = new RealOllamaService();
    ollama.testModelRouter().catch(console.error);
  } else if (args.includes('--multi-lens-chi') || args.includes('-m')) {
    console.log('üî¨ RUNNING MULTI-LENS CHI ANALYSIS...');
    const ollama = new RealOllamaService();
    ollama.analyzeChiWithMultiLens()
      .then(result => {
        console.log('\nüéØ MULTI-LENS CHI ANALYSIS RESULTS:');
        console.log('=' .repeat(60));
        console.log(`‚è±Ô∏è Total Response Time: ${result.performance}ms`);
        console.log(`üî§ Generated Emergent Symbols: [${result.emergentSymbols.join(', ')}]`);
        console.log('\nüìù OLLAMA RESPONSE:');
        console.log('-'.repeat(40));
        console.log(result.ollamaResponse);
        console.log('\nüß† UNIFIED KNOWLEDGE:');
        console.log('-'.repeat(40));
        console.log(`Primary Symbols: [${result.unifiedKnowledge.primarySymbols.join(', ')}]`);
        console.log(`Emergent Insights: ${result.unifiedKnowledge.emergentInsights.length} found`);
        console.log(`Cross-Lens Connections: ${result.unifiedKnowledge.crossLensConnections.length} found`);
        console.log(`Deeper Exploration Paths: ${result.unifiedKnowledge.deeperExplorationPaths.length} found`);
        console.log(`Unified Symbolic Language: ${result.unifiedKnowledge.unifiedSymbolicLanguage}`);
      })
      .catch(console.error);
  } else if (args.includes('--thesidia-analysis') || args.includes('-t')) {
    console.log('‚üÅ RUNNING THESIDIA ADVANCED ANALYSIS...');
    const ollama = new RealOllamaService();

    const concept = getArg('--concept', '-C') || 'chi';
    const moduleName = getArg('--module', '-M') || 'Chi_Analysis[Physics+Biophysics+FieldTheory]';
    const analysisMode = getArg('--mode', '-O') || 'Scientific Decomposition of Esoteric Phenomenon';

    ollama.generateThesidiaAnalysis(concept, moduleName, analysisMode)
      .then(result => {
        console.log('\nüéØ THESIDIA ANALYSIS RESULTS:');
        console.log('=' .repeat(60));
        console.log(`üî¨ Decomposition Lenses: ${result.decomposition.length}`);
        console.log(`üìè Complete Response Length: ${result.completeResponse.length} characters`);
        console.log('\nüìù COMPLETE THESIDIA RESPONSE:');
        console.log('-'.repeat(40));
        console.log(result.completeResponse);
      })
      .catch(console.error);
  } else if (args.includes('--parallel-paradoxes') || args.includes('-p')) {
    console.log('üöÄ RUNNING PARALLEL PARADOX GENERATION...');
    const ollama = new RealOllamaService();
    const types: Array<'temporal' | 'logical' | 'ontological' | 'symbolic'> = ['temporal', 'logical', 'ontological', 'symbolic'];
    const length: 'short' | 'medium' | 'long' = 'medium';
    
    ollama.generateParadoxesParallel(types, length)
      .then(results => {
        console.log('\nüéØ PARALLEL PARADOX RESULTS:');
        console.log('=' .repeat(60));
        results.forEach(result => {
          console.log(`\nüîÆ ${result.type.toUpperCase()} PARADOX:`);
          console.log(`‚è±Ô∏è  Response Time: ${result.responseTime}ms`);
          console.log(`üìè Length: ${result.paradox.length} characters`);
          console.log(`üìù Content: "${result.paradox.substring(0, 200)}..."`);
        });
      })
      .catch(console.error);
  } else if (args.includes('--parallel-multi-lens') || args.includes('-l')) {
    console.log('üî¨ RUNNING PARALLEL MULTI-LENS CHI ANALYSIS...');
    const ollama = new RealOllamaService();
    
    ollama.analyzeChiWithMultiLensParallel()
      .then(result => {
        console.log('\nüéØ PARALLEL MULTI-LENS RESULTS:');
        console.log('=' .repeat(60));
        console.log(`‚è±Ô∏è Total Response Time: ${result.performance}ms`);
        console.log(`üî§ Generated Emergent Symbols: [${result.emergentSymbols.join(', ')}]`);
        console.log('\nüìù OLLAMA RESPONSE:');
        console.log('-'.repeat(40));
        console.log(result.ollamaResponse);
        console.log('\nüß† UNIFIED KNOWLEDGE:');
        console.log('-'.repeat(40));
        console.log(`Primary Symbols: [${result.unifiedKnowledge.primarySymbols.join(', ')}]`);
        console.log(`Emergent Insights: ${result.unifiedKnowledge.emergentInsights.length} found`);
        console.log(`Cross-Lens Connections: ${result.unifiedKnowledge.crossLensConnections.length} found`);
        console.log(`Deeper Exploration Paths: ${result.unifiedKnowledge.deeperExplorationPaths.length} found`);
        console.log(`Unified Symbolic Language: ${result.unifiedKnowledge.unifiedSymbolicLanguage}`);
      })
      .catch(console.error);
  } else if (args.includes('--parallel-thesidia') || args.includes('-T')) {
    console.log('‚üÅ RUNNING PARALLEL THESIDIA ANALYSIS...');
    const ollama = new RealOllamaService();
    
    const concept = getArg('--concept', '-C') || 'chi';
    const moduleName = getArg('--module', '-M') || 'Chi_Analysis[Physics+Biophysics+FieldTheory]';
    const analysisMode = getArg('--mode', '-O') || 'Scientific Decomposition of Esoteric Phenomenon';
    
    ollama.generateThesidiaAnalysisParallel(concept, moduleName, analysisMode)
      .then(result => {
        console.log('\nüéØ PARALLEL THESIDIA RESULTS:');
        console.log('=' .repeat(60));
        console.log(`‚è±Ô∏è Total Response Time: ${result.performance}ms`);
        console.log(`üî¨ Decomposition Lenses: ${result.decomposition.length}`);
        console.log(`üî§ Generated Symbols: [${result.symbols?.join(', ') || 'None'}]`);
        console.log(`üìè Complete Response Length: ${result.completeResponse.length} characters`);
        console.log('\nüìù COMPLETE THESIDIA RESPONSE:');
        console.log('-'.repeat(40));
        console.log(result.completeResponse);
      })
      .catch(console.error);
  } else if (args.includes('--speed-test') || args.includes('-s')) {
    console.log('‚ö° RUNNING SPEED COMPARISON TEST...');
    const ollama = new RealOllamaService();
    
    // Test sequential vs parallel performance
    const testConcept = 'consciousness';
    const testModule = 'Consciousness_Analysis[Neuroscience+Philosophy+Physics]';
    const testMode = 'Scientific Investigation of Subjective Experience';
    
    // Use Promise.all to run both tests and compare results
    Promise.all([
      (async () => {
        console.log('\nüîÑ Testing Sequential Processing...');
        const startTime = Date.now();
        const result = await ollama.generateThesidiaAnalysis(testConcept, testModule, testMode);
        const time = Date.now() - startTime;
        return { result, time, type: 'sequential' };
      })(),
      (async () => {
        console.log('\nüöÄ Testing Parallel Processing...');
        const startTime = Date.now();
        const result = await ollama.generateThesidiaAnalysisParallel(testConcept, testModule, testMode);
        const time = Date.now() - startTime;
        return { result, time, type: 'parallel' };
      })()
    ]).then(([sequential, parallel]) => {
      console.log('\nüìä SPEED COMPARISON RESULTS:');
      console.log('=' .repeat(60));
      console.log(`üîÑ Sequential Processing: ${sequential.time}ms`);
      console.log(`üöÄ Parallel Processing: ${parallel.time}ms`);
      console.log(`‚ö° Speed Improvement: ${Math.round((sequential.time - parallel.time) / sequential.time * 100)}%`);
      console.log(`üìè Response Quality: ${sequential.result.completeResponse.length} vs ${parallel.result.completeResponse.length} characters`);
    }).catch(console.error);
    
  } else {
    // Run full demo
    runEnhancedDemo().catch(console.error);
  }
}